{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C71ntYux94gE"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EJOdC3y_LM5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a93dtQn5-BQj",
    "outputId": "b6dd0e87-d8fb-4bd2-cd54-1f4ad3cc8434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NZ2qGdL-DkB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('drive/My Drive/Telecom_customer churn (100000).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXeWn2tZ-EWx"
   },
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "change_mou=num_df['change_mou']\n",
    "change_rev=num_df['change_rev']\n",
    "num_df=num_df.drop(['change_mou'], axis=1)\n",
    "num_df=num_df.drop(['change_rev'], axis=1)\n",
    "\n",
    "num_df=num_df.drop(['Customer_ID'], axis=1)\n",
    "\n",
    "churn=num_df['churn']\n",
    "num_df=num_df.drop(['churn'], axis=1)\n",
    "\n",
    "#no convertion\n",
    "\n",
    "num_df=num_df.fillna(conData)\n",
    "\n",
    "num_df[num_df < 0]=0\n",
    "\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "result_df_op=result_df\n",
    "#result_df_op=result_df_op.drop(['churn'], axis=1)\n",
    "#result_df_op=np.nan_to_num(result_df_op)\n",
    "\n",
    "X=result_df_op\n",
    "#y=result_df['churn'] \n",
    "y=churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pArX1vH_-Phh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0, random_state=42)\n",
    "#train=pd.concat([X_train, y_train], axis=1)\n",
    "#test=pd.concat([X_test, y_test], axis=1)\n",
    "train=pd.concat([X, y], axis=1)\n",
    "test=pd.concat([X, y], axis=1)\n",
    "X_train=X\n",
    "X_test=X\n",
    "y_train=y\n",
    "y_test=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlzrGsdz-cGg"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os, sys\n",
    "file_path = 'drive/My Drive/Colab Notebooks/private-data-generation/'\n",
    "#sys.path.append(file_path)\n",
    "sys.path.append(os.path.abspath(file_path))\n",
    "import sys\n",
    "sys.path.insert(1,'/content/drive/My Drive/Colab Notebooks/private-data-generation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_XQ2M7H-eM_"
   },
   "outputs": [],
   "source": [
    "from models import dp_wgan, pate_gan, ron_gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3l37MCS-iBg"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "from models import dp_wgan, pate_gan, ron_gauss\n",
    "from models.Private_PGM import private_pgm\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NgpckIHs-eTf"
   },
   "outputs": [],
   "source": [
    "class  Class_opt:\n",
    "    \"This is a person class\"\n",
    "    categorical = False\n",
    "    model='dp-wgan'\n",
    "    target_epsilon=80\n",
    "    target_delta=0.8\n",
    "    downstream_task=\"classification\"\n",
    "    target_variable='status'\n",
    "    batch_size=64\n",
    "    micro_batch_size=8\n",
    "    clamp_lower=0.01\n",
    "    clamp_upper=0.01\n",
    "    clip_coeff=0.1\n",
    "    sigma=2.0\n",
    "    num_epochs=50\n",
    "    enable_privacy=0\n",
    "    \n",
    " \n",
    "        \n",
    "\n",
    "opt = Class_opt()\n",
    "opt.target_variable='churn'\n",
    "opt.categorical = True\n",
    "opt.model='dp-wgan'\n",
    "opt.target_epsilon=10\n",
    "opt.target_delta=0.1\n",
    "opt.batch_size=64\n",
    "opt.micro_batch_size=8\n",
    "opt.clamp_lower=0.01\n",
    "opt.clamp_upper=0.01\n",
    "opt.clip_coeff=0.1\n",
    "opt.sigma=0.8\n",
    "opt.num_epochs=200\n",
    "opt.enable_privacy=1\n",
    "\n",
    "opt.downstream_task=\"classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTiMgAjc-eWf"
   },
   "outputs": [],
   "source": [
    "data_columns = [col for col in train.columns if col != opt.target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72DPHCJp-eZS",
    "outputId": "932ace6d-c91d-42b6-fce2-6f2ee66cbabf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50438, 0.49562])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ratios = train[opt.target_variable].sort_values().groupby(train[opt.target_variable]).size().values/train.shape[0]\n",
    "class_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30XOtNBv-ebg"
   },
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(train.drop([opt.target_variable], axis=1).values)\n",
    "y_train = np.nan_to_num(train[opt.target_variable].values)\n",
    "X_test = np.nan_to_num(test.drop([opt.target_variable], axis=1).values)\n",
    "y_test = np.nan_to_num(test[opt.target_variable].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-fsH8zI-ed9"
   },
   "outputs": [],
   "source": [
    "#Normalized the data\n",
    "X_train = expit(X_train)\n",
    "X_test = expit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0L13SnRt-ei9"
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "z_dim = int(input_dim / 4 + 1) if input_dim % 4 == 0 else int(input_dim / 4)\n",
    "\n",
    "Hyperparams = collections.namedtuple('Hyperarams','batch_size micro_batch_size clamp_lower clamp_upper clip_coeff sigma class_ratios lr num_epochs')\n",
    "Hyperparams.__new__.__defaults__ = (None, None, None, None, None, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uz2Y-lDN-elZ",
    "outputId": "ab9655bb-6d43-43e6-97a2-2a0896026b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss D real :  0.3875087958023634 Loss D fake :  0.011936870525085966 Loss G :  0.01132754086818584 Epsilon spent :  1.4604744918270696\n",
      "Epoch : 2 Loss D real :  0.383797765640979 Loss D fake :  0.010219747594863915 Loss G :  0.010175761699929769 Epsilon spent :  1.4818333005328603\n",
      "Epoch : 3 Loss D real :  0.38944818624226274 Loss D fake :  0.01 Loss G :  0.010055584390954515 Epsilon spent :  1.5031921092386513\n",
      "Epoch : 4 Loss D real :  0.3826154452307542 Loss D fake :  0.01 Loss G :  0.01005055244671806 Epsilon spent :  1.5245509179444423\n",
      "Epoch : 5 Loss D real :  0.38771386390010515 Loss D fake :  0.01 Loss G :  0.01004876100567867 Epsilon spent :  1.5459097266502333\n",
      "Epoch : 6 Loss D real :  0.3866187578666139 Loss D fake :  0.01 Loss G :  0.010050376444995979 Epsilon spent :  1.567268535356024\n",
      "Epoch : 7 Loss D real :  0.3784039238134151 Loss D fake :  0.01 Loss G :  0.010049707875652706 Epsilon spent :  1.588627344061815\n",
      "Epoch : 8 Loss D real :  0.3907707356170249 Loss D fake :  0.01 Loss G :  0.010049063417719366 Epsilon spent :  1.609986152767606\n",
      "Epoch : 9 Loss D real :  0.3833061957806114 Loss D fake :  0.01 Loss G :  0.010050918355103274 Epsilon spent :  1.6313449614733968\n",
      "Epoch : 10 Loss D real :  0.38463488393009554 Loss D fake :  0.01 Loss G :  0.01005010576214292 Epsilon spent :  1.6527037701791878\n",
      "Epoch : 11 Loss D real :  0.3822994684910181 Loss D fake :  0.01 Loss G :  0.010050247428546844 Epsilon spent :  1.6740625788849788\n",
      "Epoch : 12 Loss D real :  0.3842639565825938 Loss D fake :  0.01 Loss G :  0.010052135851127068 Epsilon spent :  1.6954213875907695\n",
      "Epoch : 13 Loss D real :  0.3887962021196728 Loss D fake :  0.01 Loss G :  0.010048348542166522 Epsilon spent :  1.7167801962965605\n",
      "Epoch : 14 Loss D real :  0.38640331632397196 Loss D fake :  0.01 Loss G :  0.01005019529607221 Epsilon spent :  1.7381390050023515\n",
      "Epoch : 15 Loss D real :  0.38577103902915244 Loss D fake :  0.01 Loss G :  0.010050256446203014 Epsilon spent :  1.7594978137081423\n",
      "Epoch : 16 Loss D real :  0.3912499909439101 Loss D fake :  0.01 Loss G :  0.010050724504528517 Epsilon spent :  1.7808566224139333\n",
      "Epoch : 17 Loss D real :  0.38667679130646804 Loss D fake :  0.01 Loss G :  0.010049116172409785 Epsilon spent :  1.8022154311197243\n",
      "Epoch : 18 Loss D real :  0.38863816222420056 Loss D fake :  0.01 Loss G :  0.010050639106991907 Epsilon spent :  1.8235742398255153\n",
      "Epoch : 19 Loss D real :  0.3831145748051435 Loss D fake :  0.01 Loss G :  0.010050260628491294 Epsilon spent :  1.8364667720975436\n",
      "Epoch : 20 Loss D real :  0.3877613964227784 Loss D fake :  0.01 Loss G :  0.010048443889465472 Epsilon spent :  1.846559568636736\n",
      "Epoch : 21 Loss D real :  0.38700115817705427 Loss D fake :  0.01 Loss G :  0.010050614155255481 Epsilon spent :  1.8566523651759284\n",
      "Epoch : 22 Loss D real :  0.3822484115946218 Loss D fake :  0.01 Loss G :  0.010050244441604147 Epsilon spent :  1.8667451617151207\n",
      "Epoch : 23 Loss D real :  0.3892593346356813 Loss D fake :  0.01 Loss G :  0.010050606766283178 Epsilon spent :  1.8768379582543129\n",
      "Epoch : 24 Loss D real :  0.37956699426199564 Loss D fake :  0.01 Loss G :  0.010048717450885784 Epsilon spent :  1.8869307547935052\n",
      "Epoch : 25 Loss D real :  0.3796134619175987 Loss D fake :  0.01 Loss G :  0.010050342401916145 Epsilon spent :  1.8970235513326976\n",
      "Epoch : 26 Loss D real :  0.38523548226294074 Loss D fake :  0.01 Loss G :  0.010050394594599677 Epsilon spent :  1.9071163478718898\n",
      "Epoch : 27 Loss D real :  0.38329958423539146 Loss D fake :  0.01 Loss G :  0.010049798675037667 Epsilon spent :  1.9172091444110821\n",
      "Epoch : 28 Loss D real :  0.3887058892013325 Loss D fake :  0.01 Loss G :  0.010049648239782756 Epsilon spent :  1.9273019409502745\n",
      "Epoch : 29 Loss D real :  0.386433896688143 Loss D fake :  0.01 Loss G :  0.010049620570949144 Epsilon spent :  1.9373947374894667\n",
      "Epoch : 30 Loss D real :  0.39302870096909304 Loss D fake :  0.01 Loss G :  0.010050489337743856 Epsilon spent :  1.947487534028659\n",
      "Epoch : 31 Loss D real :  0.3862132112194241 Loss D fake :  0.01 Loss G :  0.010050883226765004 Epsilon spent :  1.9575803305678514\n",
      "Epoch : 32 Loss D real :  0.3928870492566411 Loss D fake :  0.01 Loss G :  0.010051092660179287 Epsilon spent :  1.9676731271070436\n",
      "Epoch : 33 Loss D real :  0.38735620425868544 Loss D fake :  0.01 Loss G :  0.010049454725319424 Epsilon spent :  1.977765923646236\n",
      "Epoch : 34 Loss D real :  0.38816465240764264 Loss D fake :  0.01 Loss G :  0.010050023917316853 Epsilon spent :  1.9878587201854283\n",
      "Epoch : 35 Loss D real :  0.38080250598256193 Loss D fake :  0.01 Loss G :  0.010047551981629715 Epsilon spent :  1.9979515167246205\n",
      "Epoch : 36 Loss D real :  0.3881191253876227 Loss D fake :  0.01 Loss G :  0.01004835225453053 Epsilon spent :  2.008044313263813\n",
      "Epoch : 37 Loss D real :  0.3764631868573434 Loss D fake :  0.01 Loss G :  0.010048761526094284 Epsilon spent :  2.018137109803005\n",
      "Epoch : 38 Loss D real :  0.38621374095985317 Loss D fake :  0.01 Loss G :  0.010050976046202071 Epsilon spent :  2.0282299063421974\n",
      "Epoch : 39 Loss D real :  0.3883885903998121 Loss D fake :  0.01 Loss G :  0.010049596502715766 Epsilon spent :  2.03832270288139\n",
      "Epoch : 40 Loss D real :  0.37509677802676195 Loss D fake :  0.01 Loss G :  0.010050671384201921 Epsilon spent :  2.048415499420582\n",
      "Epoch : 41 Loss D real :  0.3834654843772882 Loss D fake :  0.01 Loss G :  0.01005142011156808 Epsilon spent :  2.0585082959597742\n",
      "Epoch : 42 Loss D real :  0.3904499102340724 Loss D fake :  0.01 Loss G :  0.010049765148046619 Epsilon spent :  2.068601092498967\n",
      "Epoch : 43 Loss D real :  0.38603717641356766 Loss D fake :  0.01 Loss G :  0.010050864317294307 Epsilon spent :  2.078693889038159\n",
      "Epoch : 44 Loss D real :  0.3877314895491968 Loss D fake :  0.01 Loss G :  0.01005105073887146 Epsilon spent :  2.088786685577351\n",
      "Epoch : 45 Loss D real :  0.382760128755513 Loss D fake :  0.01 Loss G :  0.010048672396718538 Epsilon spent :  2.0988794821165437\n",
      "Epoch : 46 Loss D real :  0.38865850694685006 Loss D fake :  0.01 Loss G :  0.010051541331028636 Epsilon spent :  2.108972278655736\n",
      "Epoch : 47 Loss D real :  0.3869867553526136 Loss D fake :  0.01 Loss G :  0.010049914203148581 Epsilon spent :  2.1190650751949285\n",
      "Epoch : 48 Loss D real :  0.39109322463193574 Loss D fake :  0.01 Loss G :  0.010051131442475493 Epsilon spent :  2.1291578717341206\n",
      "Epoch : 49 Loss D real :  0.38252584438111326 Loss D fake :  0.01 Loss G :  0.010049242884622148 Epsilon spent :  2.139250668273313\n",
      "Epoch : 50 Loss D real :  0.38441401465597913 Loss D fake :  0.01 Loss G :  0.010050264947276828 Epsilon spent :  2.149343464812505\n",
      "Epoch : 51 Loss D real :  0.3913842846704243 Loss D fake :  0.01 Loss G :  0.010050398882156444 Epsilon spent :  2.1594362613516975\n",
      "Epoch : 52 Loss D real :  0.38485711712251436 Loss D fake :  0.01 Loss G :  0.01004754211069358 Epsilon spent :  2.1695290578908897\n",
      "Epoch : 53 Loss D real :  0.3895927739168412 Loss D fake :  0.01 Loss G :  0.010049868618364408 Epsilon spent :  2.1796218544300823\n",
      "Epoch : 54 Loss D real :  0.38876653722817206 Loss D fake :  0.01 Loss G :  0.010050702780072172 Epsilon spent :  2.1897146509692744\n",
      "Epoch : 55 Loss D real :  0.38452263416957844 Loss D fake :  0.01 Loss G :  0.010051152254763166 Epsilon spent :  2.1998074475084666\n",
      "Epoch : 56 Loss D real :  0.39007046784037525 Loss D fake :  0.01 Loss G :  0.01004942490299902 Epsilon spent :  2.209900244047659\n",
      "Epoch : 57 Loss D real :  0.3916023596569987 Loss D fake :  0.01 Loss G :  0.010049084567503811 Epsilon spent :  2.2199930405868513\n",
      "Epoch : 58 Loss D real :  0.381511745482747 Loss D fake :  0.01 Loss G :  0.010051579170087704 Epsilon spent :  2.230085837126044\n",
      "Epoch : 59 Loss D real :  0.379205568189247 Loss D fake :  0.01 Loss G :  0.010052268189876581 Epsilon spent :  2.240178633665236\n",
      "Epoch : 60 Loss D real :  0.38436351841344674 Loss D fake :  0.01 Loss G :  0.01005030587980987 Epsilon spent :  2.250271430204428\n",
      "Epoch : 61 Loss D real :  0.3878425118425343 Loss D fake :  0.01 Loss G :  0.010048406199791301 Epsilon spent :  2.2603642267436204\n",
      "Epoch : 62 Loss D real :  0.3851272951865672 Loss D fake :  0.01 Loss G :  0.010049698496719299 Epsilon spent :  2.270457023282813\n",
      "Epoch : 63 Loss D real :  0.39007653488910654 Loss D fake :  0.01 Loss G :  0.010051663381357013 Epsilon spent :  2.280549819822005\n",
      "Epoch : 64 Loss D real :  0.3808406596231998 Loss D fake :  0.01 Loss G :  0.010048371574352214 Epsilon spent :  2.2906426163611977\n",
      "Epoch : 65 Loss D real :  0.3746400034336874 Loss D fake :  0.01 Loss G :  0.010048065527378434 Epsilon spent :  2.30073541290039\n",
      "Epoch : 66 Loss D real :  0.3783398917983541 Loss D fake :  0.01 Loss G :  0.010049623426473312 Epsilon spent :  2.310828209439582\n",
      "Epoch : 67 Loss D real :  0.386334271905853 Loss D fake :  0.01 Loss G :  0.010052138239874883 Epsilon spent :  2.320921005978774\n",
      "Epoch : 68 Loss D real :  0.3928369457203924 Loss D fake :  0.01 Loss G :  0.010048156930004807 Epsilon spent :  2.3310138025179667\n",
      "Epoch : 69 Loss D real :  0.3824868733533095 Loss D fake :  0.01 Loss G :  0.010047878606668722 Epsilon spent :  2.341106599057159\n",
      "Epoch : 70 Loss D real :  0.38787021329960164 Loss D fake :  0.01 Loss G :  0.010049493381859268 Epsilon spent :  2.3511993955963515\n",
      "Epoch : 71 Loss D real :  0.3870584372835032 Loss D fake :  0.01 Loss G :  0.010051016777482777 Epsilon spent :  2.3612921921355436\n",
      "Epoch : 72 Loss D real :  0.3870205235897765 Loss D fake :  0.01 Loss G :  0.010049809276767548 Epsilon spent :  2.371384988674736\n",
      "Epoch : 73 Loss D real :  0.3849247777440242 Loss D fake :  0.01 Loss G :  0.010049940253861847 Epsilon spent :  2.3814777852139284\n",
      "Epoch : 74 Loss D real :  0.38568484477471016 Loss D fake :  0.01 Loss G :  0.0100514507068792 Epsilon spent :  2.3915705817531205\n",
      "Epoch : 75 Loss D real :  0.3845072277962808 Loss D fake :  0.01 Loss G :  0.010049411539845184 Epsilon spent :  2.4016633782923127\n",
      "Epoch : 76 Loss D real :  0.390398250556586 Loss D fake :  0.01 Loss G :  0.010049430957752547 Epsilon spent :  2.4117561748315053\n",
      "Epoch : 77 Loss D real :  0.38302345760872775 Loss D fake :  0.01 Loss G :  0.010050333146538226 Epsilon spent :  2.4218489713706974\n",
      "Epoch : 78 Loss D real :  0.37998518451192037 Loss D fake :  0.01 Loss G :  0.010050888568292731 Epsilon spent :  2.4319417679098896\n",
      "Epoch : 79 Loss D real :  0.39018814541087266 Loss D fake :  0.01 Loss G :  0.010050352196088066 Epsilon spent :  2.442034564449082\n",
      "Epoch : 80 Loss D real :  0.37984491650412017 Loss D fake :  0.01 Loss G :  0.01004881642029726 Epsilon spent :  2.4521273609882743\n",
      "Epoch : 81 Loss D real :  0.38720815430194905 Loss D fake :  0.01 Loss G :  0.010049879134699588 Epsilon spent :  2.462220157527467\n",
      "Epoch : 82 Loss D real :  0.3890303317917142 Loss D fake :  0.01 Loss G :  0.010050034391501386 Epsilon spent :  2.472312954066659\n",
      "Epoch : 83 Loss D real :  0.3922618360573761 Loss D fake :  0.01 Loss G :  0.010051150861382288 Epsilon spent :  2.4824057506058512\n",
      "Epoch : 84 Loss D real :  0.38692707403710497 Loss D fake :  0.01 Loss G :  0.010050645218902688 Epsilon spent :  2.4924985471450434\n",
      "Epoch : 85 Loss D real :  0.3916945343369559 Loss D fake :  0.01 Loss G :  0.01004915278575052 Epsilon spent :  2.502591343684236\n",
      "Epoch : 86 Loss D real :  0.38497727192493203 Loss D fake :  0.01 Loss G :  0.010050787764892719 Epsilon spent :  2.512684140223428\n",
      "Epoch : 87 Loss D real :  0.3861719896719811 Loss D fake :  0.01 Loss G :  0.010049754825840286 Epsilon spent :  2.5227769367626207\n",
      "Epoch : 88 Loss D real :  0.3834496302539244 Loss D fake :  0.01 Loss G :  0.010049793217909463 Epsilon spent :  2.532869733301813\n",
      "Epoch : 89 Loss D real :  0.3898581045503924 Loss D fake :  0.01 Loss G :  0.010049317370247663 Epsilon spent :  2.542962529841005\n",
      "Epoch : 90 Loss D real :  0.3857149558689452 Loss D fake :  0.01 Loss G :  0.010047342376710101 Epsilon spent :  2.5530553263801976\n",
      "Epoch : 91 Loss D real :  0.3833506291968647 Loss D fake :  0.01 Loss G :  0.010051049662099644 Epsilon spent :  2.5631481229193898\n",
      "Epoch : 92 Loss D real :  0.39320937353898955 Loss D fake :  0.01 Loss G :  0.01005030734757987 Epsilon spent :  2.573240919458582\n",
      "Epoch : 93 Loss D real :  0.385914828432218 Loss D fake :  0.01 Loss G :  0.01004839746781887 Epsilon spent :  2.5833337159977745\n",
      "Epoch : 94 Loss D real :  0.38665056569493333 Loss D fake :  0.01 Loss G :  0.010049825413527322 Epsilon spent :  2.5934265125369667\n",
      "Epoch : 95 Loss D real :  0.38256049074212606 Loss D fake :  0.01 Loss G :  0.010049956937923285 Epsilon spent :  2.603519309076159\n",
      "Epoch : 96 Loss D real :  0.38735506747530857 Loss D fake :  0.01 Loss G :  0.010048755113223236 Epsilon spent :  2.6136121056153514\n",
      "Epoch : 97 Loss D real :  0.3857946985744982 Loss D fake :  0.01 Loss G :  0.010049176641834792 Epsilon spent :  2.6237049021545436\n",
      "Epoch : 98 Loss D real :  0.38420057622821885 Loss D fake :  0.01 Loss G :  0.010046618319384526 Epsilon spent :  2.633797698693736\n",
      "Epoch : 99 Loss D real :  0.38997483547070166 Loss D fake :  0.01 Loss G :  0.010049695511789981 Epsilon spent :  2.6438904952329283\n",
      "Epoch : 100 Loss D real :  0.3828411242471646 Loss D fake :  0.01 Loss G :  0.010049873410017493 Epsilon spent :  2.6539832917721204\n",
      "Epoch : 101 Loss D real :  0.39277503641828515 Loss D fake :  0.01 Loss G :  0.010048898955995575 Epsilon spent :  2.6640760883113126\n",
      "Epoch : 102 Loss D real :  0.386871698310339 Loss D fake :  0.01 Loss G :  0.010050654184108878 Epsilon spent :  2.674168884850505\n",
      "Epoch : 103 Loss D real :  0.3813571194678024 Loss D fake :  0.01 Loss G :  0.010048664397892973 Epsilon spent :  2.6842616813896973\n",
      "Epoch : 104 Loss D real :  0.38547440990754567 Loss D fake :  0.01 Loss G :  0.010051832263069712 Epsilon spent :  2.69435447792889\n",
      "Epoch : 105 Loss D real :  0.38729275215255154 Loss D fake :  0.01 Loss G :  0.010048625265825787 Epsilon spent :  2.704447274468082\n",
      "Epoch : 106 Loss D real :  0.38286219753825157 Loss D fake :  0.01 Loss G :  0.01005051273040953 Epsilon spent :  2.7145400710072742\n",
      "Epoch : 107 Loss D real :  0.39031495215603723 Loss D fake :  0.01 Loss G :  0.010050109251739254 Epsilon spent :  2.7246328675464664\n",
      "Epoch : 108 Loss D real :  0.3887403875124998 Loss D fake :  0.01 Loss G :  0.010048884791353014 Epsilon spent :  2.734725664085659\n",
      "Epoch : 109 Loss D real :  0.38519310563615594 Loss D fake :  0.01 Loss G :  0.010050406469449108 Epsilon spent :  2.7448184606248516\n",
      "Epoch : 110 Loss D real :  0.3888432842099181 Loss D fake :  0.01 Loss G :  0.010049381814533588 Epsilon spent :  2.7549112571640437\n",
      "Epoch : 111 Loss D real :  0.38374285892613735 Loss D fake :  0.01 Loss G :  0.010050181311320147 Epsilon spent :  2.765004053703236\n",
      "Epoch : 112 Loss D real :  0.3850701764046598 Loss D fake :  0.01 Loss G :  0.010050848646986476 Epsilon spent :  2.775096850242428\n",
      "Epoch : 113 Loss D real :  0.38688036137101 Loss D fake :  0.01 Loss G :  0.010049303947891726 Epsilon spent :  2.78518964678162\n",
      "Epoch : 114 Loss D real :  0.38341244298516775 Loss D fake :  0.01 Loss G :  0.010049827319942417 Epsilon spent :  2.7952824433208128\n",
      "Epoch : 115 Loss D real :  0.38156481870989345 Loss D fake :  0.01 Loss G :  0.010049364821097584 Epsilon spent :  2.8053752398600054\n",
      "Epoch : 116 Loss D real :  0.38275282611870665 Loss D fake :  0.01 Loss G :  0.010049930301020436 Epsilon spent :  2.8154680363991975\n",
      "Epoch : 117 Loss D real :  0.3802265712895456 Loss D fake :  0.01 Loss G :  0.010050308495684163 Epsilon spent :  2.8255608329383897\n",
      "Epoch : 118 Loss D real :  0.38736500162508114 Loss D fake :  0.01 Loss G :  0.010049140323246178 Epsilon spent :  2.835653629477582\n",
      "Epoch : 119 Loss D real :  0.38613888057280366 Loss D fake :  0.01 Loss G :  0.010048537630817238 Epsilon spent :  2.8457464260167744\n",
      "Epoch : 120 Loss D real :  0.38317784155583084 Loss D fake :  0.01 Loss G :  0.010050728874461018 Epsilon spent :  2.8558392225559666\n",
      "Epoch : 121 Loss D real :  0.38577066446512137 Loss D fake :  0.01 Loss G :  0.010050791314956054 Epsilon spent :  2.865932019095159\n",
      "Epoch : 122 Loss D real :  0.38624368111273133 Loss D fake :  0.01 Loss G :  0.010050297534730595 Epsilon spent :  2.8760248156343513\n",
      "Epoch : 123 Loss D real :  0.3825923363859687 Loss D fake :  0.01 Loss G :  0.010049708651779742 Epsilon spent :  2.8861176121735435\n",
      "Epoch : 124 Loss D real :  0.38731072281030543 Loss D fake :  0.01 Loss G :  0.010049794493769046 Epsilon spent :  2.8962104087127356\n",
      "Epoch : 125 Loss D real :  0.38608278028980814 Loss D fake :  0.01 Loss G :  0.010050010859324212 Epsilon spent :  2.906303205251928\n",
      "Epoch : 126 Loss D real :  0.384564425388941 Loss D fake :  0.01 Loss G :  0.010049822842852718 Epsilon spent :  2.916396001791121\n",
      "Epoch : 127 Loss D real :  0.3779809906221444 Loss D fake :  0.01 Loss G :  0.010051595919959666 Epsilon spent :  2.926488798330313\n",
      "Epoch : 128 Loss D real :  0.3847165259320309 Loss D fake :  0.01 Loss G :  0.010048604974580412 Epsilon spent :  2.936581594869505\n",
      "Epoch : 129 Loss D real :  0.38402330419218145 Loss D fake :  0.01 Loss G :  0.010050728833801129 Epsilon spent :  2.9466743914086972\n",
      "Epoch : 130 Loss D real :  0.384359471075664 Loss D fake :  0.01 Loss G :  0.010051425329925699 Epsilon spent :  2.9567671879478894\n",
      "Epoch : 131 Loss D real :  0.38322620034821775 Loss D fake :  0.01 Loss G :  0.010050664457986072 Epsilon spent :  2.966859984487082\n",
      "Epoch : 132 Loss D real :  0.38730237315740335 Loss D fake :  0.01 Loss G :  0.010049755005815572 Epsilon spent :  2.9769527810262746\n",
      "Epoch : 133 Loss D real :  0.3849297953828349 Loss D fake :  0.01 Loss G :  0.010049964864698198 Epsilon spent :  2.9870455775654667\n",
      "Epoch : 134 Loss D real :  0.38507963971480064 Loss D fake :  0.01 Loss G :  0.010050110272494542 Epsilon spent :  2.997138374104659\n",
      "Epoch : 135 Loss D real :  0.3873989740650115 Loss D fake :  0.01 Loss G :  0.010052004267628726 Epsilon spent :  3.007231170643851\n",
      "Epoch : 136 Loss D real :  0.38055377907915167 Loss D fake :  0.01 Loss G :  0.010050003362658752 Epsilon spent :  3.0173239671830436\n",
      "Epoch : 137 Loss D real :  0.38725958932040694 Loss D fake :  0.01 Loss G :  0.010048763605279095 Epsilon spent :  3.027416763722236\n",
      "Epoch : 138 Loss D real :  0.3929218116244975 Loss D fake :  0.01 Loss G :  0.01004946151191599 Epsilon spent :  3.0375095602614284\n",
      "Epoch : 139 Loss D real :  0.3952539719859917 Loss D fake :  0.01 Loss G :  0.010048347827427717 Epsilon spent :  3.0476023568006205\n",
      "Epoch : 140 Loss D real :  0.3838963048126561 Loss D fake :  0.01 Loss G :  0.010050587187878934 Epsilon spent :  3.0576951533398127\n",
      "Epoch : 141 Loss D real :  0.38897651245475595 Loss D fake :  0.01 Loss G :  0.010051078059914467 Epsilon spent :  3.067787949879005\n",
      "Epoch : 142 Loss D real :  0.38073291026142564 Loss D fake :  0.01 Loss G :  0.010048267094431212 Epsilon spent :  3.0778807464181974\n",
      "Epoch : 143 Loss D real :  0.38105193770631884 Loss D fake :  0.01 Loss G :  0.010051303431844275 Epsilon spent :  3.08797354295739\n",
      "Epoch : 144 Loss D real :  0.3877013533855075 Loss D fake :  0.01 Loss G :  0.010050883090222 Epsilon spent :  3.098066339496582\n",
      "Epoch : 145 Loss D real :  0.3880458872047017 Loss D fake :  0.01 Loss G :  0.010051339525391932 Epsilon spent :  3.1081591360357743\n",
      "Epoch : 146 Loss D real :  0.38512953363209557 Loss D fake :  0.01 Loss G :  0.0100486346823328 Epsilon spent :  3.1182519325749665\n",
      "Epoch : 147 Loss D real :  0.38741778834759344 Loss D fake :  0.01 Loss G :  0.01004940463428483 Epsilon spent :  3.1283447291141586\n",
      "Epoch : 148 Loss D real :  0.39152289608341345 Loss D fake :  0.01 Loss G :  0.010049868721402512 Epsilon spent :  3.138437525653351\n",
      "Epoch : 149 Loss D real :  0.38891470334877415 Loss D fake :  0.01 Loss G :  0.010049878028355457 Epsilon spent :  3.148530322192544\n",
      "Epoch : 150 Loss D real :  0.3837805064998405 Loss D fake :  0.01 Loss G :  0.010049468968568051 Epsilon spent :  3.158623118731736\n",
      "Epoch : 151 Loss D real :  0.3850498886436424 Loss D fake :  0.01 Loss G :  0.010051378776610857 Epsilon spent :  3.168715915270928\n",
      "Epoch : 152 Loss D real :  0.38814201473497556 Loss D fake :  0.01 Loss G :  0.010049344773378719 Epsilon spent :  3.1788087118101203\n",
      "Epoch : 153 Loss D real :  0.3825932714776647 Loss D fake :  0.01 Loss G :  0.010050688427543128 Epsilon spent :  3.188901508349313\n",
      "Epoch : 154 Loss D real :  0.3854421029045244 Loss D fake :  0.01 Loss G :  0.010049065543833875 Epsilon spent :  3.198994304888505\n",
      "Epoch : 155 Loss D real :  0.38675309927087054 Loss D fake :  0.01 Loss G :  0.010050269994047283 Epsilon spent :  3.2090871014276976\n",
      "Epoch : 156 Loss D real :  0.38170837316095163 Loss D fake :  0.01 Loss G :  0.010048237609706998 Epsilon spent :  3.2191798979668897\n",
      "Epoch : 157 Loss D real :  0.38554482813718566 Loss D fake :  0.01 Loss G :  0.010051958512775563 Epsilon spent :  3.229272694506082\n",
      "Epoch : 158 Loss D real :  0.3874256102269802 Loss D fake :  0.01 Loss G :  0.010048987078397898 Epsilon spent :  3.239365491045274\n",
      "Epoch : 159 Loss D real :  0.38063605176515847 Loss D fake :  0.01 Loss G :  0.010049946678869676 Epsilon spent :  3.2494582875844666\n",
      "Epoch : 160 Loss D real :  0.38629239737557586 Loss D fake :  0.01 Loss G :  0.010050265911167753 Epsilon spent :  3.259551084123659\n",
      "Epoch : 161 Loss D real :  0.39017009415064685 Loss D fake :  0.01 Loss G :  0.010048195001812397 Epsilon spent :  3.2696438806628514\n",
      "Epoch : 162 Loss D real :  0.3843883730207277 Loss D fake :  0.01 Loss G :  0.010049458897560034 Epsilon spent :  3.2797366772020435\n",
      "Epoch : 163 Loss D real :  0.38795108202118656 Loss D fake :  0.01 Loss G :  0.010050256088823224 Epsilon spent :  3.2898294737412357\n",
      "Epoch : 164 Loss D real :  0.38257844978971034 Loss D fake :  0.01 Loss G :  0.010051198520678213 Epsilon spent :  3.299922270280428\n",
      "Epoch : 165 Loss D real :  0.37995953558755147 Loss D fake :  0.01 Loss G :  0.010050433715722066 Epsilon spent :  3.3100150668196204\n",
      "Epoch : 166 Loss D real :  0.3807850334853959 Loss D fake :  0.01 Loss G :  0.01004922701147106 Epsilon spent :  3.320107863358813\n",
      "Epoch : 167 Loss D real :  0.39271429150956044 Loss D fake :  0.01 Loss G :  0.010050329130952709 Epsilon spent :  3.330200659898005\n",
      "Epoch : 168 Loss D real :  0.3816177328753027 Loss D fake :  0.01 Loss G :  0.01004914493410688 Epsilon spent :  3.3402934564371973\n",
      "Epoch : 169 Loss D real :  0.3873161932546215 Loss D fake :  0.01 Loss G :  0.01005119460499162 Epsilon spent :  3.3503862529763895\n",
      "Epoch : 170 Loss D real :  0.38848264792237486 Loss D fake :  0.01 Loss G :  0.010050548812380532 Epsilon spent :  3.360479049515582\n",
      "Epoch : 171 Loss D real :  0.38605006911724293 Loss D fake :  0.01 Loss G :  0.010049207977447992 Epsilon spent :  3.3705718460547742\n",
      "Epoch : 172 Loss D real :  0.3886417499570155 Loss D fake :  0.01 Loss G :  0.01005096781778716 Epsilon spent :  3.380664642593967\n",
      "Epoch : 173 Loss D real :  0.37335794868158334 Loss D fake :  0.01 Loss G :  0.010048985501301504 Epsilon spent :  3.390757439133159\n",
      "Epoch : 174 Loss D real :  0.38436721710445565 Loss D fake :  0.01 Loss G :  0.0100514412151939 Epsilon spent :  3.400850235672351\n",
      "Epoch : 175 Loss D real :  0.38036508886151077 Loss D fake :  0.01 Loss G :  0.01004976611722639 Epsilon spent :  3.4109430322115433\n",
      "Epoch : 176 Loss D real :  0.3854546790785589 Loss D fake :  0.01 Loss G :  0.010049088240938127 Epsilon spent :  3.421035828750736\n",
      "Epoch : 177 Loss D real :  0.38178493102250854 Loss D fake :  0.01 Loss G :  0.010051096009653876 Epsilon spent :  3.431128625289928\n",
      "Epoch : 178 Loss D real :  0.38620900046792717 Loss D fake :  0.01 Loss G :  0.010052044512512829 Epsilon spent :  3.4412214218291206\n",
      "Epoch : 179 Loss D real :  0.386415117635766 Loss D fake :  0.01 Loss G :  0.010050604538655411 Epsilon spent :  3.4513142183683128\n",
      "Epoch : 180 Loss D real :  0.3864172111035761 Loss D fake :  0.01 Loss G :  0.010050853446874492 Epsilon spent :  3.461407014907505\n",
      "Epoch : 181 Loss D real :  0.39207375351825247 Loss D fake :  0.01 Loss G :  0.010051093512833642 Epsilon spent :  3.471499811446697\n",
      "Epoch : 182 Loss D real :  0.38990615053443145 Loss D fake :  0.01 Loss G :  0.010049769218353632 Epsilon spent :  3.4815926079858897\n",
      "Epoch : 183 Loss D real :  0.39231480961562626 Loss D fake :  0.01 Loss G :  0.010051809520123611 Epsilon spent :  3.4916854045250822\n",
      "Epoch : 184 Loss D real :  0.3864184205896448 Loss D fake :  0.01 Loss G :  0.01004884055066581 Epsilon spent :  3.5017782010642744\n",
      "Epoch : 185 Loss D real :  0.38994232675353424 Loss D fake :  0.01 Loss G :  0.010048617308887056 Epsilon spent :  3.5118709976034665\n",
      "Epoch : 186 Loss D real :  0.3899068702008322 Loss D fake :  0.01 Loss G :  0.0100511739926984 Epsilon spent :  3.5219637941426587\n",
      "Epoch : 187 Loss D real :  0.3939687324918544 Loss D fake :  0.01 Loss G :  0.010049535057444952 Epsilon spent :  3.532056590681851\n",
      "Epoch : 188 Loss D real :  0.3864026896509081 Loss D fake :  0.01 Loss G :  0.010050042083586234 Epsilon spent :  3.5421493872210434\n",
      "Epoch : 189 Loss D real :  0.3848169218467039 Loss D fake :  0.01 Loss G :  0.010049770001710598 Epsilon spent :  3.552242183760236\n",
      "Epoch : 190 Loss D real :  0.3847784148613905 Loss D fake :  0.01 Loss G :  0.010050819051903116 Epsilon spent :  3.562334980299428\n",
      "Epoch : 191 Loss D real :  0.39031717215102907 Loss D fake :  0.01 Loss G :  0.01004841990123127 Epsilon spent :  3.5724277768386203\n",
      "Epoch : 192 Loss D real :  0.38958808705846915 Loss D fake :  0.01 Loss G :  0.010050205997600672 Epsilon spent :  3.5825205733778125\n",
      "Epoch : 193 Loss D real :  0.3861493259672564 Loss D fake :  0.01 Loss G :  0.010048866502660698 Epsilon spent :  3.592613369917005\n",
      "Epoch : 194 Loss D real :  0.3884401760188333 Loss D fake :  0.01 Loss G :  0.01004978716879692 Epsilon spent :  3.6027061664561972\n",
      "Epoch : 195 Loss D real :  0.3894831298309097 Loss D fake :  0.01 Loss G :  0.01004907653985444 Epsilon spent :  3.61279896299539\n",
      "Epoch : 196 Loss D real :  0.3876677789716263 Loss D fake :  0.01 Loss G :  0.010051240584984418 Epsilon spent :  3.622891759534582\n",
      "Epoch : 197 Loss D real :  0.3883500135413719 Loss D fake :  0.01 Loss G :  0.010050747952996972 Epsilon spent :  3.632984556073774\n",
      "Epoch : 198 Loss D real :  0.3819099967708371 Loss D fake :  0.01 Loss G :  0.01005126333738197 Epsilon spent :  3.642208870379791\n",
      "Epoch : 199 Loss D real :  0.3829211503562804 Loss D fake :  0.01 Loss G :  0.010047544926571008 Epsilon spent :  3.6509128499734853\n",
      "Epoch : 200 Loss D real :  0.3835308283369143 Loss D fake :  0.01 Loss G :  0.010051430639547157 Epsilon spent :  3.659616829567179\n",
      "Epoch : 201 Loss D real :  0.388106266143891 Loss D fake :  0.01 Loss G :  0.01004923689947832 Epsilon spent :  3.668320809160873\n",
      "Epoch : 202 Loss D real :  0.38207181904259246 Loss D fake :  0.01 Loss G :  0.010049806118474102 Epsilon spent :  3.677024788754567\n",
      "Epoch : 203 Loss D real :  0.38681199557720575 Loss D fake :  0.01 Loss G :  0.01004962681182232 Epsilon spent :  3.685728768348261\n",
      "Epoch : 204 Loss D real :  0.3923077872459129 Loss D fake :  0.01 Loss G :  0.010050491985778289 Epsilon spent :  3.6944327479419554\n",
      "Epoch : 205 Loss D real :  0.3858396167110505 Loss D fake :  0.01 Loss G :  0.01004930248764817 Epsilon spent :  3.7031367275356493\n",
      "Epoch : 206 Loss D real :  0.3834584357732318 Loss D fake :  0.01 Loss G :  0.010052394310449872 Epsilon spent :  3.711840707129343\n",
      "Epoch : 207 Loss D real :  0.389388059552085 Loss D fake :  0.01 Loss G :  0.01005066231528566 Epsilon spent :  3.7205446867230374\n",
      "Epoch : 208 Loss D real :  0.39051511092801655 Loss D fake :  0.01 Loss G :  0.010049959093502243 Epsilon spent :  3.7292486663167312\n",
      "Epoch : 209 Loss D real :  0.38497416186106637 Loss D fake :  0.01 Loss G :  0.010049620890830429 Epsilon spent :  3.7379526459104255\n",
      "Epoch : 210 Loss D real :  0.38250454658826516 Loss D fake :  0.01 Loss G :  0.010050865797837337 Epsilon spent :  3.7466566255041194\n",
      "Epoch : 211 Loss D real :  0.3821761367406889 Loss D fake :  0.01 Loss G :  0.01004996989985172 Epsilon spent :  3.755360605097813\n",
      "Epoch : 212 Loss D real :  0.38173396438225926 Loss D fake :  0.01 Loss G :  0.010048112067159982 Epsilon spent :  3.7640645846915075\n",
      "Epoch : 213 Loss D real :  0.3901271179069253 Loss D fake :  0.01 Loss G :  0.010050155829304646 Epsilon spent :  3.772768564285202\n",
      "Epoch : 214 Loss D real :  0.3902209090530056 Loss D fake :  0.01 Loss G :  0.010050398445277782 Epsilon spent :  3.7814725438788956\n",
      "Epoch : 215 Loss D real :  0.3879159281457122 Loss D fake :  0.01 Loss G :  0.010049979462291869 Epsilon spent :  3.7901765234725895\n",
      "Epoch : 216 Loss D real :  0.38538328965038104 Loss D fake :  0.01 Loss G :  0.01005137904762991 Epsilon spent :  3.7988805030662833\n",
      "Epoch : 217 Loss D real :  0.38423911201627137 Loss D fake :  0.01 Loss G :  0.010050223560962267 Epsilon spent :  3.8075844826599776\n",
      "Epoch : 218 Loss D real :  0.38475011761997246 Loss D fake :  0.01 Loss G :  0.010049295148951604 Epsilon spent :  3.816288462253672\n",
      "Epoch : 219 Loss D real :  0.38399477323958253 Loss D fake :  0.01 Loss G :  0.010050509552861945 Epsilon spent :  3.8249924418473658\n",
      "Epoch : 220 Loss D real :  0.3888541850197013 Loss D fake :  0.01 Loss G :  0.010051668820507686 Epsilon spent :  3.8336964214410596\n",
      "Epoch : 221 Loss D real :  0.38677128253554677 Loss D fake :  0.01 Loss G :  0.0100497388833262 Epsilon spent :  3.842400401034754\n",
      "Epoch : 222 Loss D real :  0.38737575517406364 Loss D fake :  0.01 Loss G :  0.01005002926267034 Epsilon spent :  3.851104380628448\n",
      "Epoch : 223 Loss D real :  0.39570782419804 Loss D fake :  0.01 Loss G :  0.010050234165542188 Epsilon spent :  3.859808360222142\n",
      "Epoch : 224 Loss D real :  0.3882123146661405 Loss D fake :  0.01 Loss G :  0.010050344782158459 Epsilon spent :  3.868512339815836\n",
      "Epoch : 225 Loss D real :  0.38201389194827573 Loss D fake :  0.01 Loss G :  0.010051169440705882 Epsilon spent :  3.8772163194095297\n",
      "Epoch : 226 Loss D real :  0.3859037637603146 Loss D fake :  0.01 Loss G :  0.010049076534839297 Epsilon spent :  3.885920299003224\n",
      "Epoch : 227 Loss D real :  0.381951979819629 Loss D fake :  0.01 Loss G :  0.010048534056750323 Epsilon spent :  3.8946242785969183\n",
      "Epoch : 228 Loss D real :  0.3861260469654394 Loss D fake :  0.01 Loss G :  0.010049654712395316 Epsilon spent :  3.903328258190612\n",
      "Epoch : 229 Loss D real :  0.38932155750716346 Loss D fake :  0.01 Loss G :  0.01005016173332164 Epsilon spent :  3.912032237784306\n",
      "Epoch : 230 Loss D real :  0.38582498540792487 Loss D fake :  0.01 Loss G :  0.010048982483940625 Epsilon spent :  3.920736217378\n",
      "Epoch : 231 Loss D real :  0.3850762860226674 Loss D fake :  0.01 Loss G :  0.010051562372506347 Epsilon spent :  3.9294401969716946\n",
      "Epoch : 232 Loss D real :  0.38621309397271697 Loss D fake :  0.01 Loss G :  0.010048795322890167 Epsilon spent :  3.9381441765653884\n",
      "Epoch : 233 Loss D real :  0.3864853927655871 Loss D fake :  0.01 Loss G :  0.010050628787054575 Epsilon spent :  3.9468481561590822\n",
      "Epoch : 234 Loss D real :  0.38100170796049737 Loss D fake :  0.01 Loss G :  0.010049691993393933 Epsilon spent :  3.955552135752776\n",
      "Epoch : 235 Loss D real :  0.3810482012199097 Loss D fake :  0.01 Loss G :  0.010049402853441065 Epsilon spent :  3.964256115346471\n",
      "Epoch : 236 Loss D real :  0.3882287322412551 Loss D fake :  0.01 Loss G :  0.010049963715814856 Epsilon spent :  3.9729600949401647\n",
      "Epoch : 237 Loss D real :  0.3781705005663082 Loss D fake :  0.01 Loss G :  0.010047536194585939 Epsilon spent :  3.9816640745338585\n",
      "Epoch : 238 Loss D real :  0.38417278015055756 Loss D fake :  0.01 Loss G :  0.010049871816358216 Epsilon spent :  3.9903680541275524\n",
      "Epoch : 239 Loss D real :  0.38993103323170286 Loss D fake :  0.01 Loss G :  0.010049181265915315 Epsilon spent :  3.999072033721246\n",
      "Epoch : 240 Loss D real :  0.39089419824877886 Loss D fake :  0.01 Loss G :  0.010048594618475588 Epsilon spent :  4.007776013314941\n",
      "Epoch : 241 Loss D real :  0.38168114832493294 Loss D fake :  0.01 Loss G :  0.01004927791651521 Epsilon spent :  4.016479992908635\n",
      "Epoch : 242 Loss D real :  0.38602765608560874 Loss D fake :  0.01 Loss G :  0.010048512450000047 Epsilon spent :  4.025183972502329\n",
      "Epoch : 243 Loss D real :  0.3876211375245243 Loss D fake :  0.01 Loss G :  0.01004792021031281 Epsilon spent :  4.0338879520960225\n",
      "Epoch : 244 Loss D real :  0.38494659958737254 Loss D fake :  0.01 Loss G :  0.010051443353271166 Epsilon spent :  4.042591931689716\n",
      "Epoch : 245 Loss D real :  0.3877121162461755 Loss D fake :  0.01 Loss G :  0.010051147095170136 Epsilon spent :  4.051295911283411\n",
      "Epoch : 246 Loss D real :  0.379575369231144 Loss D fake :  0.01 Loss G :  0.01004912914779272 Epsilon spent :  4.059999890877105\n",
      "Epoch : 247 Loss D real :  0.3883718894458209 Loss D fake :  0.01 Loss G :  0.010049764996102162 Epsilon spent :  4.068703870470799\n",
      "Epoch : 248 Loss D real :  0.38664774402037205 Loss D fake :  0.01 Loss G :  0.010048764012850321 Epsilon spent :  4.077407850064493\n",
      "Epoch : 249 Loss D real :  0.3805710738349125 Loss D fake :  0.01 Loss G :  0.010051392166325246 Epsilon spent :  4.086111829658187\n",
      "Epoch : 250 Loss D real :  0.38259104751413925 Loss D fake :  0.01 Loss G :  0.01005126483394305 Epsilon spent :  4.094815809251881\n",
      "Epoch : 251 Loss D real :  0.3807130435803947 Loss D fake :  0.01 Loss G :  0.010050534145038925 Epsilon spent :  4.103519788845575\n",
      "Epoch : 252 Loss D real :  0.390706146340688 Loss D fake :  0.01 Loss G :  0.010050333724162691 Epsilon spent :  4.112223768439269\n",
      "Epoch : 253 Loss D real :  0.3889860552206871 Loss D fake :  0.01 Loss G :  0.010050365665320206 Epsilon spent :  4.120927748032963\n",
      "Epoch : 254 Loss D real :  0.3873319046323951 Loss D fake :  0.01 Loss G :  0.010052263462665224 Epsilon spent :  4.129631727626657\n",
      "Epoch : 255 Loss D real :  0.3868141096215686 Loss D fake :  0.01 Loss G :  0.01004928330672763 Epsilon spent :  4.138335707220351\n",
      "Epoch : 256 Loss D real :  0.3853434139131718 Loss D fake :  0.01 Loss G :  0.01005086263498564 Epsilon spent :  4.147039686814045\n",
      "Epoch : 257 Loss D real :  0.38446130472134 Loss D fake :  0.01 Loss G :  0.010050737716012057 Epsilon spent :  4.155743666407739\n",
      "Epoch : 258 Loss D real :  0.38198126018551204 Loss D fake :  0.01 Loss G :  0.01004911094202808 Epsilon spent :  4.164447646001434\n",
      "Epoch : 259 Loss D real :  0.3887660377626727 Loss D fake :  0.01 Loss G :  0.010049949992586026 Epsilon spent :  4.1731516255951275\n",
      "Epoch : 260 Loss D real :  0.38432910367357376 Loss D fake :  0.01 Loss G :  0.010050384739482405 Epsilon spent :  4.181855605188821\n",
      "Epoch : 261 Loss D real :  0.39160112622240845 Loss D fake :  0.01 Loss G :  0.01005078931470538 Epsilon spent :  4.190559584782515\n",
      "Epoch : 262 Loss D real :  0.3800636202583766 Loss D fake :  0.01 Loss G :  0.010052310119976305 Epsilon spent :  4.199263564376209\n",
      "Epoch : 263 Loss D real :  0.3903880488174343 Loss D fake :  0.01 Loss G :  0.01005142777634964 Epsilon spent :  4.207967543969904\n",
      "Epoch : 264 Loss D real :  0.38560122769882055 Loss D fake :  0.01 Loss G :  0.010049512160282737 Epsilon spent :  4.216671523563598\n",
      "Epoch : 265 Loss D real :  0.38959286178821884 Loss D fake :  0.01 Loss G :  0.01005122151611185 Epsilon spent :  4.2253755031572915\n",
      "Epoch : 266 Loss D real :  0.3791929222319986 Loss D fake :  0.01 Loss G :  0.010049950777033167 Epsilon spent :  4.234079482750985\n",
      "Epoch : 267 Loss D real :  0.3867048784283065 Loss D fake :  0.01 Loss G :  0.010050616711375747 Epsilon spent :  4.242783462344679\n",
      "Epoch : 268 Loss D real :  0.3861377228583107 Loss D fake :  0.01 Loss G :  0.010048870481570642 Epsilon spent :  4.251487441938374\n",
      "Epoch : 269 Loss D real :  0.3819159731560791 Loss D fake :  0.01 Loss G :  0.010048395524825865 Epsilon spent :  4.260191421532068\n",
      "Epoch : 270 Loss D real :  0.3813481935685482 Loss D fake :  0.01 Loss G :  0.010049467179996064 Epsilon spent :  4.268895401125762\n",
      "Epoch : 271 Loss D real :  0.38245544031758594 Loss D fake :  0.01 Loss G :  0.010052195348487227 Epsilon spent :  4.2775993807194554\n",
      "Epoch : 272 Loss D real :  0.38670190152695316 Loss D fake :  0.01 Loss G :  0.010052555670825216 Epsilon spent :  4.28630336031315\n",
      "Epoch : 273 Loss D real :  0.39036599402108463 Loss D fake :  0.01 Loss G :  0.010048486853756193 Epsilon spent :  4.295007339906844\n",
      "Epoch : 274 Loss D real :  0.385207973443976 Loss D fake :  0.01 Loss G :  0.010049302215275082 Epsilon spent :  4.303711319500538\n",
      "Epoch : 275 Loss D real :  0.37882495239127606 Loss D fake :  0.01 Loss G :  0.010049772242078425 Epsilon spent :  4.312415299094232\n",
      "Epoch : 276 Loss D real :  0.3830634328808039 Loss D fake :  0.01 Loss G :  0.010048805533671015 Epsilon spent :  4.321119278687926\n",
      "Epoch : 277 Loss D real :  0.3891617405764778 Loss D fake :  0.01 Loss G :  0.010051173299214683 Epsilon spent :  4.32982325828162\n",
      "Epoch : 278 Loss D real :  0.3868675600552822 Loss D fake :  0.01 Loss G :  0.010049994847324368 Epsilon spent :  4.338527237875314\n",
      "Epoch : 279 Loss D real :  0.384807029860576 Loss D fake :  0.01 Loss G :  0.010050552475972084 Epsilon spent :  4.347231217469008\n",
      "Epoch : 280 Loss D real :  0.3870218990190879 Loss D fake :  0.01 Loss G :  0.010051521085932269 Epsilon spent :  4.355935197062702\n",
      "Epoch : 281 Loss D real :  0.39354787571077854 Loss D fake :  0.01 Loss G :  0.01004978888070683 Epsilon spent :  4.364639176656397\n",
      "Epoch : 282 Loss D real :  0.3843527101164833 Loss D fake :  0.01 Loss G :  0.010050467473260803 Epsilon spent :  4.37334315625009\n",
      "Epoch : 283 Loss D real :  0.3807118078604909 Loss D fake :  0.01 Loss G :  0.010053452568256283 Epsilon spent :  4.382047135843784\n",
      "Epoch : 284 Loss D real :  0.3798236600232935 Loss D fake :  0.01 Loss G :  0.010049120772900043 Epsilon spent :  4.390751115437478\n",
      "Epoch : 285 Loss D real :  0.38555903719413687 Loss D fake :  0.01 Loss G :  0.010050958741559911 Epsilon spent :  4.399455095031172\n",
      "Epoch : 286 Loss D real :  0.3835400609002317 Loss D fake :  0.01 Loss G :  0.010050446894143172 Epsilon spent :  4.408159074624867\n",
      "Epoch : 287 Loss D real :  0.38921394880758825 Loss D fake :  0.01 Loss G :  0.010051259124430353 Epsilon spent :  4.4168630542185605\n",
      "Epoch : 288 Loss D real :  0.38683190617464197 Loss D fake :  0.01 Loss G :  0.010048087808372585 Epsilon spent :  4.425567033812254\n",
      "Epoch : 289 Loss D real :  0.379571221330413 Loss D fake :  0.01 Loss G :  0.010049951303952918 Epsilon spent :  4.434271013405948\n",
      "Epoch : 290 Loss D real :  0.39004376360607135 Loss D fake :  0.01 Loss G :  0.010050109254008177 Epsilon spent :  4.442974992999643\n",
      "Epoch : 291 Loss D real :  0.3840712649249702 Loss D fake :  0.01 Loss G :  0.010051520071002752 Epsilon spent :  4.451678972593337\n",
      "Epoch : 292 Loss D real :  0.38352522552897517 Loss D fake :  0.01 Loss G :  0.010049107177970574 Epsilon spent :  4.460382952187031\n",
      "Epoch : 293 Loss D real :  0.3883876022268562 Loss D fake :  0.01 Loss G :  0.01004996799260056 Epsilon spent :  4.4690869317807245\n",
      "Epoch : 294 Loss D real :  0.38498743022563775 Loss D fake :  0.01 Loss G :  0.010049017454821951 Epsilon spent :  4.477790911374418\n",
      "Epoch : 295 Loss D real :  0.3878152906384975 Loss D fake :  0.01 Loss G :  0.010051436914236666 Epsilon spent :  4.486494890968113\n",
      "Epoch : 296 Loss D real :  0.3895257075240576 Loss D fake :  0.01 Loss G :  0.010050145272491092 Epsilon spent :  4.495198870561807\n",
      "Epoch : 297 Loss D real :  0.3840892100332625 Loss D fake :  0.01 Loss G :  0.010049485175991479 Epsilon spent :  4.503447068277823\n",
      "Epoch : 298 Loss D real :  0.38610463897955194 Loss D fake :  0.01 Loss G :  0.010050756766183255 Epsilon spent :  4.510857377958914\n",
      "Epoch : 299 Loss D real :  0.38097164848880305 Loss D fake :  0.01 Loss G :  0.010049057416150158 Epsilon spent :  4.518267687640003\n",
      "Epoch : 300 Loss D real :  0.38372387486246917 Loss D fake :  0.01 Loss G :  0.01004903605733139 Epsilon spent :  4.525677997321093\n",
      "Epoch : 301 Loss D real :  0.3888163761049839 Loss D fake :  0.01 Loss G :  0.010048374290977102 Epsilon spent :  4.533088307002184\n",
      "Epoch : 302 Loss D real :  0.3860268027405615 Loss D fake :  0.01 Loss G :  0.010051499315582402 Epsilon spent :  4.540498616683274\n",
      "Epoch : 303 Loss D real :  0.3865210641417451 Loss D fake :  0.01 Loss G :  0.010050814226658255 Epsilon spent :  4.547908926364364\n",
      "Epoch : 304 Loss D real :  0.38775641916190356 Loss D fake :  0.01 Loss G :  0.010048230521123335 Epsilon spent :  4.555319236045454\n",
      "Epoch : 305 Loss D real :  0.38696785643428505 Loss D fake :  0.01 Loss G :  0.010050822372504212 Epsilon spent :  4.562729545726544\n",
      "Epoch : 306 Loss D real :  0.3895649499919316 Loss D fake :  0.01 Loss G :  0.01004849430594652 Epsilon spent :  4.570139855407635\n",
      "Epoch : 307 Loss D real :  0.38321639374922334 Loss D fake :  0.01 Loss G :  0.010050632872528399 Epsilon spent :  4.577550165088725\n",
      "Epoch : 308 Loss D real :  0.3863563007369507 Loss D fake :  0.01 Loss G :  0.010050088872841105 Epsilon spent :  4.584960474769815\n",
      "Epoch : 309 Loss D real :  0.3848514198987172 Loss D fake :  0.01 Loss G :  0.010051842018819403 Epsilon spent :  4.592370784450905\n",
      "Epoch : 310 Loss D real :  0.38543581562751184 Loss D fake :  0.01 Loss G :  0.010049013071675033 Epsilon spent :  4.599781094131995\n",
      "Epoch : 311 Loss D real :  0.3787820561800088 Loss D fake :  0.01 Loss G :  0.01005042380418673 Epsilon spent :  4.6071914038130855\n",
      "Epoch : 312 Loss D real :  0.38551367325187946 Loss D fake :  0.01 Loss G :  0.010050302181724388 Epsilon spent :  4.614601713494176\n",
      "Epoch : 313 Loss D real :  0.3864652156182378 Loss D fake :  0.01 Loss G :  0.010051752141713428 Epsilon spent :  4.622012023175266\n",
      "Epoch : 314 Loss D real :  0.3905972441448561 Loss D fake :  0.01 Loss G :  0.01005065676381503 Epsilon spent :  4.629422332856356\n",
      "Epoch : 315 Loss D real :  0.39321065447364956 Loss D fake :  0.01 Loss G :  0.010049522567173985 Epsilon spent :  4.6368326425374455\n",
      "Epoch : 316 Loss D real :  0.38293710621401866 Loss D fake :  0.01 Loss G :  0.010049335681084714 Epsilon spent :  4.644242952218536\n",
      "Epoch : 317 Loss D real :  0.38261915861740636 Loss D fake :  0.01 Loss G :  0.010049871576601562 Epsilon spent :  4.651653261899627\n",
      "Epoch : 318 Loss D real :  0.3820443312770161 Loss D fake :  0.01 Loss G :  0.010051950966684323 Epsilon spent :  4.659063571580717\n",
      "Epoch : 319 Loss D real :  0.38483970527048206 Loss D fake :  0.01 Loss G :  0.01004981814354227 Epsilon spent :  4.6664738812618065\n",
      "Epoch : 320 Loss D real :  0.3874968254695085 Loss D fake :  0.01 Loss G :  0.010050983349869999 Epsilon spent :  4.673884190942896\n",
      "Epoch : 321 Loss D real :  0.38636324643231823 Loss D fake :  0.01 Loss G :  0.010051003196114221 Epsilon spent :  4.681294500623987\n",
      "Epoch : 322 Loss D real :  0.38902312678373696 Loss D fake :  0.01 Loss G :  0.010049046182646456 Epsilon spent :  4.688704810305078\n",
      "Epoch : 323 Loss D real :  0.39002773670283697 Loss D fake :  0.01 Loss G :  0.010048889240477962 Epsilon spent :  4.6961151199861675\n",
      "Epoch : 324 Loss D real :  0.3846158910007696 Loss D fake :  0.01 Loss G :  0.010049122863039465 Epsilon spent :  4.703525429667257\n",
      "Epoch : 325 Loss D real :  0.3805276716020566 Loss D fake :  0.01 Loss G :  0.010048651476165292 Epsilon spent :  4.710935739348347\n",
      "Epoch : 326 Loss D real :  0.3858045996820846 Loss D fake :  0.01 Loss G :  0.01005137582480781 Epsilon spent :  4.718346049029438\n",
      "Epoch : 327 Loss D real :  0.38502137990745944 Loss D fake :  0.01 Loss G :  0.01005003627032056 Epsilon spent :  4.7257563587105285\n",
      "Epoch : 328 Loss D real :  0.38725467041208506 Loss D fake :  0.01 Loss G :  0.010049736082965704 Epsilon spent :  4.733166668391618\n",
      "Epoch : 329 Loss D real :  0.385491196072302 Loss D fake :  0.01 Loss G :  0.010051672850163118 Epsilon spent :  4.740576978072708\n"
     ]
    }
   ],
   "source": [
    "conditional = (opt.downstream_task == \"classification\")\n",
    "model = dp_wgan.DP_WGAN(input_dim, z_dim, opt.target_epsilon, opt.target_delta, conditional)\n",
    "model.train(X_train, y_train, Hyperparams(batch_size=opt.batch_size, micro_batch_size=opt.micro_batch_size,\n",
    "                                              clamp_lower=opt.clamp_lower, clamp_upper=opt.clamp_upper,\n",
    "                                              clip_coeff=opt.clip_coeff, sigma=opt.sigma, class_ratios=class_ratios, lr=\n",
    "                                              5e-5, num_epochs=opt.num_epochs), private=opt.enable_privacy)\n",
    "\n",
    "torch.save(model, 'drive/My Drive/checkpoint_GAN_MWOE_privacy_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgmVMwIs-eni"
   },
   "outputs": [],
   "source": [
    "if opt.model == 'imle' or opt.model == 'dp-wgan' or opt.model == 'pate-gan':\n",
    "    syn_data = model.generate(X_train.shape[0], class_ratios)\n",
    "    X_syn, y_syn = syn_data[:, :-1], syn_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVHDjtpZ-eqP"
   },
   "outputs": [],
   "source": [
    "X_syn_df = pd.DataFrame(data=X_syn, columns=data_columns)\n",
    "y_syn_df = pd.DataFrame(data=y_syn, columns=[opt.target_variable])\n",
    "\n",
    "syn_df = pd.concat([X_syn_df, y_syn_df], axis=1)\n",
    "syn_df.to_csv(\"drive/My Drive/synthetic_data_GAN_mWOE_privacy_1_100percent.csv\")\n",
    "print(\"Saved synthetic data at : \", \"drive/My Drive/synthetic_data_GAN_mWOE_privacy_1_100percent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDFf_cSc-evW"
   },
   "outputs": [],
   "source": [
    "# Creating downstream learners\n",
    "learners = []\n",
    "if opt.downstream_task == \"classification\":\n",
    "    names = ['LR', 'Random Forest', 'Neural Network', 'GaussianNB', 'GradientBoostingClassifier', 'DT', 'KNN', 'SVN']\n",
    "\n",
    "    learners.append((LogisticRegression()))\n",
    "    learners.append((RandomForestClassifier()))\n",
    "    learners.append((MLPClassifier(early_stopping=True)))\n",
    "    learners.append((GaussianNB()))\n",
    "    learners.append((GradientBoostingClassifier()))\n",
    "    learners.append(DecisionTreeClassifier())\n",
    "    learners.append((KNeighborsClassifier()))\n",
    "    #learners.append((svm.SVC()))\n",
    "\n",
    "    print(\"AUC scores of downstream classifiers on test data : \")\n",
    "    for i in range(0, len(learners)):\n",
    "        score = learners[i].fit(X_syn, y_syn)\n",
    "        #score = learners[i].fit(X_train, y_train)\n",
    "        pred_probs = learners[i].predict_proba(X_test)\n",
    "        auc_score = roc_auc_score(y_test, pred_probs[:, 1])\n",
    "        print('-' * 40)\n",
    "        print('{0}: {1}'.format(names[i], auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_G9KVrg-exy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YDT5In3-e1N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQ-APCXJ-e23"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnWV3KbP-e5p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QS-PQ06L-e89"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngzlHAS4-e_b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFEZ96NO-fBf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN-mWOE-privacy_1_100percent gan trained.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
