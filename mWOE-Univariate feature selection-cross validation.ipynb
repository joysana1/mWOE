{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"Telecom_customer churn (100000).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "change_mou=num_df['change_mou']\n",
    "change_rev=num_df['change_rev']\n",
    "num_df=num_df.drop(['change_mou'], axis=1)\n",
    "num_df=num_df.drop(['change_rev'], axis=1)\n",
    "\n",
    "num_df=num_df.drop(['Customer_ID'], axis=1)\n",
    "\n",
    "churn=num_df['churn']\n",
    "num_df=num_df.drop(['churn'], axis=1)\n",
    "\n",
    "\n",
    "num_df=num_df.fillna(conData)\n",
    "\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "result_df_op=result_df\n",
    "\n",
    "X=result_df_op\n",
    "y=churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class WOE_Encoder():\n",
    "    def __init__(self, cols=None, size=None):\n",
    "            self.cols = cols\n",
    "            self.min_samples=1\n",
    "            #self.bins=10000\n",
    "            self.bins=int(size/10)\n",
    "            self._mapping = {}\n",
    "            \n",
    "    def WOE_fit(self, X, y):\n",
    "        for col in self.cols:\n",
    "            X[col]=X[col].fillna(-9999)\n",
    "            if (len(np.unique(X[col]))>100):\n",
    "                binned_x = pd.qcut(X[col], self.bins,  duplicates='drop')\n",
    "                d0 = pd.DataFrame({'x': binned_x, 'y':y})\n",
    "            else:\n",
    "                d0 = pd.DataFrame({'x': X[col], 'y': y})\n",
    "            #print (d0)\n",
    "            # Share of positive (resp. negative) labels for each category P(X=X_i | Y=1) (resp. P(X=X_i | Y=0))\n",
    "            #mapping = y.groupby(X[col]).agg(['sum', 'count']).rename({'sum': 'pos'}, axis=1)\n",
    "            mapping = y.groupby(d0[\"x\"]).agg(['sum', 'count']).rename({'sum': 'pos'}, axis=1)\n",
    "            mapping['neg'] = mapping['count'] - mapping['pos']\n",
    "            mapping[['pos', 'neg']] /= mapping[['pos', 'neg']].sum()\n",
    "            # For corner cases, defaulting to WOE = 0 (meaning no info). To avoid division by 0 we use default values.\n",
    "            undef = (mapping['count'] < self.min_samples) | (mapping['pos'] == 0) | (mapping['neg'] == 0)\n",
    "            mapping.loc[undef, ['pos', 'neg']] = -1\n",
    "            # Final step, log of ratio of probabily estimates\n",
    "            mapping['value'] = np.log((mapping['pos'] +0.0001)/ (mapping['neg']+0.0001))\n",
    "            #mapping['value'] = np.log((mapping['pos'])/ (mapping['neg']))\n",
    "            self._mapping[col] = mapping\n",
    "            \n",
    "\n",
    "        X_encoded = X.copy(deep=True)\n",
    "        for col, mapping in self._mapping.items():\n",
    "            X_encoded.loc[:, col] = X_encoded[col].fillna(-9999).map(mapping['value'])\n",
    "            X_encoded[col].fillna(0, inplace=True)\n",
    "             \n",
    "        return X_encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>drop_vce_Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>infobase</th>\n",
       "      <th>HHstatin</th>\n",
       "      <th>dwllsize</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104470</td>\n",
       "      <td>0.436563</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>-0.015254</td>\n",
       "      <td>-0.014729</td>\n",
       "      <td>-0.033738</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>-0.011625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025599</td>\n",
       "      <td>-0.036977</td>\n",
       "      <td>-0.045577</td>\n",
       "      <td>-0.028542</td>\n",
       "      <td>-0.002808</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326524</td>\n",
       "      <td>-0.113140</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>-0.167096</td>\n",
       "      <td>-0.099569</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025599</td>\n",
       "      <td>-0.036977</td>\n",
       "      <td>-0.045577</td>\n",
       "      <td>-0.399273</td>\n",
       "      <td>-0.002808</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007083</td>\n",
       "      <td>0.581470</td>\n",
       "      <td>0.093368</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>-0.015254</td>\n",
       "      <td>-0.014729</td>\n",
       "      <td>-0.033738</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>-0.011625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025599</td>\n",
       "      <td>-0.036977</td>\n",
       "      <td>-0.045577</td>\n",
       "      <td>-0.028542</td>\n",
       "      <td>-0.002808</td>\n",
       "      <td>0.042984</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104470</td>\n",
       "      <td>0.168960</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>-0.015254</td>\n",
       "      <td>-0.014729</td>\n",
       "      <td>-0.033738</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.126064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025599</td>\n",
       "      <td>-0.036977</td>\n",
       "      <td>0.051638</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.110607</td>\n",
       "      <td>-0.212196</td>\n",
       "      <td>-0.081971</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>-0.015254</td>\n",
       "      <td>-0.014729</td>\n",
       "      <td>-0.033738</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.065281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025599</td>\n",
       "      <td>-0.036977</td>\n",
       "      <td>-0.036787</td>\n",
       "      <td>0.066163</td>\n",
       "      <td>-0.002808</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0  0.104470  0.436563     0.014151  0.032513    -0.015254    -0.014729   \n",
       "1  0.326524 -0.113140     0.006570  0.032513     0.016397    -0.167096   \n",
       "2 -0.007083  0.581470     0.093368  0.032513    -0.015254    -0.014729   \n",
       "3  0.104470  0.168960     0.005006  0.032513    -0.015254    -0.014729   \n",
       "4 -0.110607 -0.212196    -0.081971  0.032513    -0.015254    -0.014729   \n",
       "\n",
       "   vceovr_Mean  datovr_Mean  roam_Mean  drop_vce_Mean  ...  infobase  \\\n",
       "0    -0.033738     0.018839   0.014623      -0.011625  ... -0.025599   \n",
       "1    -0.099569     0.018839   0.014623       0.000000  ... -0.025599   \n",
       "2    -0.033738     0.018839   0.014623      -0.011625  ... -0.025599   \n",
       "3    -0.033738     0.018839   0.014623       0.126064  ... -0.025599   \n",
       "4    -0.033738     0.018839   0.014623       0.065281  ... -0.025599   \n",
       "\n",
       "   HHstatin  dwllsize    ethnic    kid0_2    kid3_5   kid6_10  kid11_15  \\\n",
       "0 -0.036977 -0.045577 -0.028542 -0.002808 -0.000904  0.002464   0.00339   \n",
       "1 -0.036977 -0.045577 -0.399273 -0.002808 -0.000904  0.002464   0.00339   \n",
       "2 -0.036977 -0.045577 -0.028542 -0.002808  0.042984  0.002464   0.00339   \n",
       "3 -0.036977  0.051638  0.018417  0.095089 -0.000904  0.002464   0.00339   \n",
       "4 -0.036977 -0.036787  0.066163 -0.002808 -0.000904  0.002464   0.00339   \n",
       "\n",
       "   kid16_17  creditcd  \n",
       "0 -0.001641 -0.021628  \n",
       "1 -0.001641 -0.021628  \n",
       "2 -0.001641 -0.021628  \n",
       "3 -0.001641 -0.021628  \n",
       "4 -0.001641 -0.021628  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Obj = WOE_Encoder(cols=X.columns, size=X.shape[0])\n",
    "X_encoded = Obj.WOE_fit(X, y)\n",
    "X_encoded.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>drop_vce_Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>infobase</th>\n",
       "      <th>HHstatin</th>\n",
       "      <th>dwllsize</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104470</td>\n",
       "      <td>0.436563</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.581470</td>\n",
       "      <td>0.093368</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042984</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104470</td>\n",
       "      <td>0.168960</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.126064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051638</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.065281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0  0.104470  0.436563     0.014151  0.032513     0.000000          0.0   \n",
       "1  0.326524  0.000000     0.006570  0.032513     0.016397          0.0   \n",
       "2  0.000000  0.581470     0.093368  0.032513     0.000000          0.0   \n",
       "3  0.104470  0.168960     0.005006  0.032513     0.000000          0.0   \n",
       "4  0.000000  0.000000     0.000000  0.032513     0.000000          0.0   \n",
       "\n",
       "   vceovr_Mean  datovr_Mean  roam_Mean  drop_vce_Mean  ...  infobase  \\\n",
       "0          0.0     0.018839   0.014623       0.000000  ...       0.0   \n",
       "1          0.0     0.018839   0.014623       0.000000  ...       0.0   \n",
       "2          0.0     0.018839   0.014623       0.000000  ...       0.0   \n",
       "3          0.0     0.018839   0.014623       0.126064  ...       0.0   \n",
       "4          0.0     0.018839   0.014623       0.065281  ...       0.0   \n",
       "\n",
       "   HHstatin  dwllsize    ethnic    kid0_2    kid3_5   kid6_10  kid11_15  \\\n",
       "0       0.0  0.000000  0.000000  0.000000  0.000000  0.002464   0.00339   \n",
       "1       0.0  0.000000  0.000000  0.000000  0.000000  0.002464   0.00339   \n",
       "2       0.0  0.000000  0.000000  0.000000  0.042984  0.002464   0.00339   \n",
       "3       0.0  0.051638  0.018417  0.095089  0.000000  0.002464   0.00339   \n",
       "4       0.0  0.000000  0.066163  0.000000  0.000000  0.002464   0.00339   \n",
       "\n",
       "   kid16_17  creditcd  \n",
       "0       0.0       0.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "3       0.0       0.0  \n",
       "4       0.0       0.0  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded[X_encoded < 0]=0\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 96)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>totrev</td>\n",
       "      <td>2175.877612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>adjrev</td>\n",
       "      <td>2106.491811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>avgmou</td>\n",
       "      <td>1990.140359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>adjmou</td>\n",
       "      <td>1821.804528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>totmou</td>\n",
       "      <td>1811.764599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>truck</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>kid11_15</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>kid6_10</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>forgntvl</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>rv</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature       Scores\n",
       "51    totrev  2175.877612\n",
       "52    adjrev  2106.491811\n",
       "56    avgmou  1990.140359\n",
       "53    adjmou  1821.804528\n",
       "50    totmou  1811.764599\n",
       "..       ...          ...\n",
       "67     truck     0.000947\n",
       "93  kid11_15     0.000871\n",
       "92   kid6_10     0.000337\n",
       "73  forgntvl     0.000308\n",
       "68        rv     0.000180\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X_encoded\n",
    "y_train=y\n",
    "#Univariate Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "select_feature = SelectKBest(chi2, k=90).fit(X_train, y_train)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                     'Scores':select_feature.scores_})\n",
    "selected_features_df.sort_values(by='Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 90)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=y\n",
    "x_train_chi = select_feature.transform(X_train)\n",
    "x_train_chi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42561 7877 19449 30113\n",
      "pod:  0.6075824220168677\n",
      "pof:  0.15617193385939174\n",
      "AUC:  0.725705244078738\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.0533669923120631}\n",
      "GaussianNB(var_smoothing=0.0533669923120631)\n",
      "0.77013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=5, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "classifier=GaussianNB();\n",
    "#params = {\n",
    "#          \"priors\" : \"None\",\n",
    "#          \"var_smoothing\" : 1e-9\n",
    "#}\n",
    "#create an list of var_smoothing to cross validate\n",
    "#steps = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "grid = GridSearchCV(estimator=classifier, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    " \n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42396 8042 19069 30493\n",
      "pod:  0.6152495863766595\n",
      "pof:  0.15944327689440502\n",
      "AUC:  0.7279031547411273\n",
      "accuracy:  0.72889\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB(priors=None, var_smoothing=6.579332246575682e-09)\n",
    "\n",
    "classifier.fit(x_train_chi,y_train)\n",
    "\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=10, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 5)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "LogisticRegression(C=5, multi_class='ovr')\n",
      "0.84354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'C': c_values, 'penalty': ['l1'], 'solver' : ['liblinear'], 'multi_class' : ['ovr']},    \n",
    "    {'C': c_values, 'penalty': ['l2'], 'solver' : ['liblinear', 'newton-cg', 'lbfgs'], 'multi_class' : ['ovr']}\n",
    "]\n",
    " \n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43083 7355 8296 41266\n",
      "pod:  0.8326136959767564\n",
      "pof:  0.14582259407589515\n",
      "AUC:  0.8433955509504307\n",
      "accuracy:  0.84349\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "classifier = LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
    "          n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 44 candidates, totalling 440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed: 74.0min\n",
      "[Parallel(n_jobs=-1)]: Done 440 out of 440 | elapsed: 196.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=8, weights='distance')\n",
      "0.7558499999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "param_grid ={\n",
    "   'n_neighbors': [3,5,8,11,15,19,22,25,27,30,32],\n",
    "   'weights': ['uniform', 'distance'],\n",
    "   'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(metric='euclidean', weights='distance', n_neighbors=8 )  \n",
    "classifier.fit(x_train_chi, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42291 8147 7281 42281\n",
      "pod:  0.8530930955167265\n",
      "pof:  0.16152504064395892\n",
      "AUC:  0.8457840274363837\n",
      "accuracy:  0.84572\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(bootstrap= True, max_depth= 80, max_features= 3, min_samples_leaf= 3, min_samples_split= 12, n_estimators= 1000)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:323: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37039 13399 14239 35323\n",
      "pod:  0.712703280739276\n",
      "pof:  0.26565288076450294\n",
      "AUC:  0.7235251999873866\n",
      "accuracy:  0.72362\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37039 13399 14239 35323\n",
      "pod:  0.712703280739276\n",
      "pof:  0.26565288076450294\n",
      "AUC:  0.7235251999873866\n",
      "accuracy:  0.72362\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier(max_features='sqrt',criterion='mae')\n",
    "#classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 12s 5ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.3255 - val_accuracy: 0.8623\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3463 - accuracy: 0.8476 - val_loss: 0.3216 - val_accuracy: 0.8634\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3418 - accuracy: 0.8489 - val_loss: 0.3209 - val_accuracy: 0.8621\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3399 - accuracy: 0.8500 - val_loss: 0.3249 - val_accuracy: 0.8647\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3312 - accuracy: 0.8567 - val_loss: 0.3241 - val_accuracy: 0.8619\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3360 - accuracy: 0.8528 - val_loss: 0.3206 - val_accuracy: 0.8647\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3342 - accuracy: 0.8516 - val_loss: 0.3199 - val_accuracy: 0.8650\n",
      "Epoch 8/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3364 - accuracy: 0.8527 - val_loss: 0.3178 - val_accuracy: 0.8649\n",
      "Epoch 9/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3328 - accuracy: 0.8525 - val_loss: 0.3261 - val_accuracy: 0.8593\n",
      "Epoch 10/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3321 - accuracy: 0.8534 - val_loss: 0.3216 - val_accuracy: 0.8627\n",
      "Epoch 11/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3302 - accuracy: 0.8547 - val_loss: 0.3162 - val_accuracy: 0.8651\n",
      "Epoch 12/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3308 - accuracy: 0.8546 - val_loss: 0.3214 - val_accuracy: 0.8589\n",
      "Epoch 13/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3296 - accuracy: 0.8549 - val_loss: 0.3188 - val_accuracy: 0.8627\n",
      "Epoch 14/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3310 - accuracy: 0.8550 - val_loss: 0.3182 - val_accuracy: 0.8634\n",
      "y2_pred:  [[0.9409889 ]\n",
      " [0.00467724]\n",
      " [0.38996744]\n",
      " ...\n",
      " [0.7010584 ]\n",
      " [0.94869995]\n",
      " [0.678811  ]]\n",
      "y22_pred:  [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.8547508573734114\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 11s 4ms/step - loss: 0.4105 - accuracy: 0.8068 - val_loss: 0.3270 - val_accuracy: 0.8625\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3464 - accuracy: 0.8462 - val_loss: 0.3306 - val_accuracy: 0.8629\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3417 - accuracy: 0.8521 - val_loss: 0.3379 - val_accuracy: 0.8493\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3368 - accuracy: 0.8520 - val_loss: 0.3234 - val_accuracy: 0.8620\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3354 - accuracy: 0.8527 - val_loss: 0.3190 - val_accuracy: 0.8646\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3351 - accuracy: 0.8525 - val_loss: 0.3218 - val_accuracy: 0.8612\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3343 - accuracy: 0.8549 - val_loss: 0.3256 - val_accuracy: 0.8627\n",
      "Epoch 8/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3338 - accuracy: 0.8527 - val_loss: 0.3225 - val_accuracy: 0.8649\n",
      "y2_pred:  [[0.09783393]\n",
      " [0.12712932]\n",
      " [0.29844356]\n",
      " ...\n",
      " [0.2966388 ]\n",
      " [0.2511458 ]\n",
      " [0.1891028 ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.8704861811579584\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 11s 4ms/step - loss: 0.4031 - accuracy: 0.8109 - val_loss: 0.3279 - val_accuracy: 0.8596\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3445 - accuracy: 0.8476 - val_loss: 0.3230 - val_accuracy: 0.8613\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3400 - accuracy: 0.8507 - val_loss: 0.3184 - val_accuracy: 0.8641\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3354 - accuracy: 0.8530 - val_loss: 0.3194 - val_accuracy: 0.8636\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3355 - accuracy: 0.8543 - val_loss: 0.3218 - val_accuracy: 0.8626\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3361 - accuracy: 0.8525 - val_loss: 0.3290 - val_accuracy: 0.8612\n",
      "y2_pred:  [[0.7166033 ]\n",
      " [0.99992096]\n",
      " [0.81019473]\n",
      " ...\n",
      " [0.41983038]\n",
      " [0.39197487]\n",
      " [0.01559168]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.8833736884584342\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 11s 4ms/step - loss: 0.4111 - accuracy: 0.8065 - val_loss: 0.3220 - val_accuracy: 0.8626\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3468 - accuracy: 0.8477 - val_loss: 0.3260 - val_accuracy: 0.8621\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3405 - accuracy: 0.8516 - val_loss: 0.3174 - val_accuracy: 0.8638\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3371 - accuracy: 0.8499 - val_loss: 0.3235 - val_accuracy: 0.8648\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3348 - accuracy: 0.8523 - val_loss: 0.3190 - val_accuracy: 0.8628\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3325 - accuracy: 0.8540 - val_loss: 0.3173 - val_accuracy: 0.8660\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3359 - accuracy: 0.8522 - val_loss: 0.3197 - val_accuracy: 0.8635\n",
      "Epoch 8/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3323 - accuracy: 0.8552 - val_loss: 0.3224 - val_accuracy: 0.8642\n",
      "Epoch 9/30\n",
      "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3333 - accuracy: 0.8550 - val_loss: 0.3189 - val_accuracy: 0.8643\n",
      "y2_pred:  [[0.39488697]\n",
      " [0.8648238 ]\n",
      " [0.38818198]\n",
      " ...\n",
      " [0.41191438]\n",
      " [0.00180364]\n",
      " [0.00832716]]\n",
      "y22_pred:  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.8430185633575464\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 12s 5ms/step - loss: 0.4136 - accuracy: 0.8028 - val_loss: 0.3291 - val_accuracy: 0.8618\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3445 - accuracy: 0.8484 - val_loss: 0.3208 - val_accuracy: 0.8628\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3413 - accuracy: 0.8491 - val_loss: 0.3248 - val_accuracy: 0.8633\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3344 - accuracy: 0.8548 - val_loss: 0.3281 - val_accuracy: 0.8623\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3366 - accuracy: 0.8522 - val_loss: 0.3260 - val_accuracy: 0.8596\n",
      "y2_pred:  [[0.8666319 ]\n",
      " [0.8725133 ]\n",
      " [0.7100653 ]\n",
      " ...\n",
      " [0.17178929]\n",
      " [0.03696457]\n",
      " [0.0745846 ]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.7746166263115416\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 12s 5ms/step - loss: 0.4013 - accuracy: 0.8127 - val_loss: 0.3291 - val_accuracy: 0.8630\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3458 - accuracy: 0.8473 - val_loss: 0.3227 - val_accuracy: 0.8614\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3406 - accuracy: 0.8500 - val_loss: 0.3289 - val_accuracy: 0.8594\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3359 - accuracy: 0.8535 - val_loss: 0.3325 - val_accuracy: 0.8592\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3369 - accuracy: 0.8536 - val_loss: 0.3201 - val_accuracy: 0.8636\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3314 - accuracy: 0.8557 - val_loss: 0.3179 - val_accuracy: 0.8656\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3340 - accuracy: 0.8536 - val_loss: 0.3200 - val_accuracy: 0.8637\n",
      "Epoch 8/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3330 - accuracy: 0.8544 - val_loss: 0.3167 - val_accuracy: 0.8654\n",
      "Epoch 9/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3332 - accuracy: 0.8533 - val_loss: 0.3192 - val_accuracy: 0.8643\n",
      "Epoch 10/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3321 - accuracy: 0.8545 - val_loss: 0.3174 - val_accuracy: 0.8660\n",
      "Epoch 11/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3320 - accuracy: 0.8549 - val_loss: 0.3284 - val_accuracy: 0.8582\n",
      "y2_pred:  [[0.73217976]\n",
      " [0.99787694]\n",
      " [0.98242885]\n",
      " ...\n",
      " [0.82196975]\n",
      " [0.01616675]\n",
      " [0.04699418]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.9158595641646489\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 12s 5ms/step - loss: 0.3973 - accuracy: 0.8147 - val_loss: 0.3273 - val_accuracy: 0.8606\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3413 - accuracy: 0.8506 - val_loss: 0.3260 - val_accuracy: 0.8587\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3359 - accuracy: 0.8512 - val_loss: 0.3221 - val_accuracy: 0.8627\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3330 - accuracy: 0.8534 - val_loss: 0.3199 - val_accuracy: 0.8641\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3303 - accuracy: 0.8549 - val_loss: 0.3199 - val_accuracy: 0.8617\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3298 - accuracy: 0.8562 - val_loss: 0.3254 - val_accuracy: 0.8594\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3313 - accuracy: 0.8542 - val_loss: 0.3185 - val_accuracy: 0.8653\n",
      "Epoch 8/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3260 - accuracy: 0.8578 - val_loss: 0.3258 - val_accuracy: 0.8582\n",
      "Epoch 9/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3291 - accuracy: 0.8565 - val_loss: 0.3220 - val_accuracy: 0.8611\n",
      "Epoch 10/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3279 - accuracy: 0.8557 - val_loss: 0.3190 - val_accuracy: 0.8662\n",
      "y2_pred:  [[0.634632  ]\n",
      " [0.9904679 ]\n",
      " [0.9715926 ]\n",
      " ...\n",
      " [0.29174712]\n",
      " [0.21326748]\n",
      " [0.2347436 ]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.8688458434221146\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 12s 5ms/step - loss: 0.4102 - accuracy: 0.8043 - val_loss: 0.3264 - val_accuracy: 0.8617\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3443 - accuracy: 0.8498 - val_loss: 0.3404 - val_accuracy: 0.8516\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3403 - accuracy: 0.8508 - val_loss: 0.3253 - val_accuracy: 0.8619\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3350 - accuracy: 0.8531 - val_loss: 0.3315 - val_accuracy: 0.8574\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3316 - accuracy: 0.8562 - val_loss: 0.3200 - val_accuracy: 0.8641\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3324 - accuracy: 0.8554 - val_loss: 0.3197 - val_accuracy: 0.8636\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3335 - accuracy: 0.8554 - val_loss: 0.3198 - val_accuracy: 0.8647\n",
      "Epoch 8/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3333 - accuracy: 0.8536 - val_loss: 0.3208 - val_accuracy: 0.8637\n",
      "Epoch 9/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3338 - accuracy: 0.8547 - val_loss: 0.3206 - val_accuracy: 0.8641\n",
      "y2_pred:  [[0.9655174 ]\n",
      " [0.23320481]\n",
      " [0.976261  ]\n",
      " ...\n",
      " [0.07603967]\n",
      " [0.00257707]\n",
      " [0.00837135]]\n",
      "y22_pred:  [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.7338579499596449\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 12s 5ms/step - loss: 0.4179 - accuracy: 0.7984 - val_loss: 0.3284 - val_accuracy: 0.8572\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3403 - accuracy: 0.8494 - val_loss: 0.3369 - val_accuracy: 0.8542\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3400 - accuracy: 0.8518 - val_loss: 0.3246 - val_accuracy: 0.8570\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3364 - accuracy: 0.8532 - val_loss: 0.3519 - val_accuracy: 0.8533\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3406 - accuracy: 0.8521 - val_loss: 0.3242 - val_accuracy: 0.8569\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3365 - accuracy: 0.8533 - val_loss: 0.3221 - val_accuracy: 0.8597\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3321 - accuracy: 0.8533 - val_loss: 0.3203 - val_accuracy: 0.8612\n",
      "Epoch 8/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3351 - accuracy: 0.8529 - val_loss: 0.3397 - val_accuracy: 0.8541\n",
      "Epoch 9/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3328 - accuracy: 0.8550 - val_loss: 0.3326 - val_accuracy: 0.8537\n",
      "Epoch 10/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3338 - accuracy: 0.8536 - val_loss: 0.3266 - val_accuracy: 0.8583\n",
      "y2_pred:  [[0.98749727]\n",
      " [0.084254  ]\n",
      " [0.5893627 ]\n",
      " ...\n",
      " [0.03575432]\n",
      " [0.20841467]\n",
      " [0.05010453]]\n",
      "y22_pred:  [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.847457627118644\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 12s 5ms/step - loss: 0.4107 - accuracy: 0.8052 - val_loss: 0.3255 - val_accuracy: 0.8608\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3458 - accuracy: 0.8478 - val_loss: 0.3735 - val_accuracy: 0.8334\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3428 - accuracy: 0.8497 - val_loss: 0.3303 - val_accuracy: 0.8616\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3372 - accuracy: 0.8518 - val_loss: 0.3192 - val_accuracy: 0.8630\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3365 - accuracy: 0.8538 - val_loss: 0.3219 - val_accuracy: 0.8644\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 11s 5ms/step - loss: 0.3366 - accuracy: 0.8526 - val_loss: 0.3518 - val_accuracy: 0.8471\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 10s 4ms/step - loss: 0.3325 - accuracy: 0.8548 - val_loss: 0.3212 - val_accuracy: 0.8624\n",
      "y2_pred:  [[0.9467516 ]\n",
      " [0.36889094]\n",
      " [0.7972145 ]\n",
      " ...\n",
      " [0.810259  ]\n",
      " [0.3749655 ]\n",
      " [0.994222  ]]\n",
      "y22_pred:  [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "pod 1st:  0.7941888619854721\n",
      "pod:  [0.8547508573734114, 0.8704861811579584, 0.8833736884584342, 0.8430185633575464, 0.7746166263115416, 0.9158595641646489, 0.8688458434221146, 0.7338579499596449, 0.847457627118644, 0.7941888619854721]\n",
      "pof:  [0.13840967677969462, 0.16458457267499504, 0.18477398889770025, 0.13996827914353688, 0.08743061062648691, 0.22244250594766057, 0.2309674861221253, 0.12053925455987312, 0.11260904044409199, 0.08128469468675655]\n",
      "auc:  [0.8581705902968584, 0.8529508042414817, 0.849299849780367, 0.8515251421070048, 0.8435930078425274, 0.8467085291084941, 0.8189391786499947, 0.8066593476998859, 0.867424293337276, 0.8564520836493578]\n",
      "tn_list:  [4345, 4213, 4112, 4338, 4603, 3922, 3879, 4436, 4476, 4634]\n",
      "fp_list:  [698, 830, 932, 706, 441, 1122, 1165, 608, 568, 410]\n",
      "fn_list:  [720, 642, 578, 778, 1117, 417, 650, 1319, 756, 1020]\n",
      "tp_list:  [4237, 4315, 4378, 4178, 3839, 4539, 4306, 3637, 4200, 3936]\n",
      "42958 7480 7997 41565\n"
     ]
    }
   ],
   "source": [
    "df_x_train_chi = pd.DataFrame(x_train_chi)\n",
    "df_x_train_chi.head()\n",
    "\n",
    "#FNN\n",
    "def get_FNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #get number of columns in training data\n",
    "    n_cols = X2_train.shape[1]\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model using mse as a measure of model performance\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    from keras.callbacks import EarlyStopping\n",
    "    #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    #train model\n",
    "    model.fit(X2_train, y2_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    print('y2_pred: ',y2_pred)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_FNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print('tn_list: ',tn_list)\n",
    "print ('fp_list: ',fp_list)\n",
    "print ('fn_list: ',fn_list)\n",
    "print ('tp_list: ',tp_list)\n",
    "\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
